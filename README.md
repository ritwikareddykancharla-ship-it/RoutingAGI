# ğŸšš RoutingAGI: Neural Optimization for Middle-Mile Logistics  
### ğŸ§  Graphormer + Mamba + Constraint-Aware MoE for Large-Scale Routing

RoutingAGI is a research framework that investigates **neural surrogates** for large-scale middle-mile routing optimization, inspired by real operational challenges in Amazon Transportation (SCOT, ATS, Middle Mile Science).  
It integrates **graph-aware encoders**, **state-space sequence models**, **constraint-aligned experts**, and **world-model forecasting** to approximate MILP-like routing behavior.

ğŸ’¡ The goal is to explore whether deep learning can capture the **structure, constraints, feasibility patterns, and multi-objective trade-offs** present in real logistics networks.

> âš ï¸ RoutingAGI is a **research prototype**, intended for experimentation and hybrid optimizationâ€”not production deployment.

---

## ğŸ” Problem Motivation

Middle-mile routing involves shipping between FC â†’ SC â†’ DS â†’ Hubs while respecting:

- ğŸš› trailer & container capacities  
- â±ï¸ time windows, cutoffs, SLAs  
- ğŸ›£ï¸ lane legality & mode constraints (air/ground)  
- âš™ï¸ sort-center throughput & bottlenecks  
- ğŸŒ region-level routing rules  
- âš–ï¸ load balancing  
- ğŸšš equipment & trailer availability  
- ğŸ’° multi-objective operational costs  

Traditional MILPs struggle under:

- large, dynamic networks  
- real-time decision needs  
- stochastic demand  
- multi-step forecasting  
- non-linear constraints  

RoutingAGI explores whether neural networks can act as **fast, differentiable surrogates** that:

- estimate feasibility and constraint violations  
- compress combinatorial decision spaces  
- support routing search or RL  
- simulate future network states  
- learn operational patterns from data  

---

## ğŸ§  Architecture Overview

## Graphormer Encoder â†’ Mamba Block â†’ Constraint-Aware MoE â†’ World Model â†’ Decoder


---

### **1. ğŸ—ºï¸ Graphormer Encoder**
Learns structural and spatial routing features:

- facility type embeddings (FC, SC, DS, Hubs)  
- lane types & legality  
- shortest-path and distance encodings  
- centrality, connectivity, and congestion signals  
- multi-hop relational context  

---

### **2. âš¡ Mamba Block (Selective State-Space Model)**
Provides temporal reasoning with linear-time scaling:

- SLA propagation  
- congestion ripple effects  
- equipment availability drift  
- scheduling dependencies  

Mambaâ€™s **selective gating + dynamic filters** make it powerful for operational sequences.

---

### **3. ğŸ§© Constraint-Aware Mixture-of-Experts**
Each expert models a MILP constraint through activation geometry.

| Constraint | Activation | Why |
|-----------|------------|-----|
| ğŸ“¦ Capacity | ReLU / Softplus | hinge-shaped overload |
| â±ï¸ Time Windows | ReLU | lateness hinge |
| âŒ Lane Legality | Sigmoid | binary feasibility |
| âš™ï¸ Throughput | Tanh / Sigmoid | saturating bottlenecks |
| ğŸš¨ SLA Risk | Softplus | convex penalty |
| ğŸ” Flow Conservation | Linear | equality constraint |
| ğŸŒ Region Rules | Softmax | categorical transitions |
| âš–ï¸ Load Balancing | Softplus | convex overload |
| ğŸšš Trailer Availability | ReLU | piecewise linear |

This layer injects **mathematical constraint structure** directly into the network.

---

### **4. ğŸ”® World Model**
Forecasts routing state evolution:

- congestion & queue buildup  
- SLA slack drift  
- trailer shortages  
- sort-center saturation  
- cross-dock propagation  

Enables multi-step simulation & planning.

---

### **5. ğŸ›ï¸ Decoder**
Outputs routing-relevant predictions:

- constraint violation likelihood  
- feasibility scores  
- route-embedding vectors  
- logits for downstream decision modules  

---

## ğŸ“¦ Repository Structure
routing_agi/
â”‚
â”œâ”€â”€ modules/
â”‚ â”œâ”€â”€ graph_encoder.py
â”‚ â”œâ”€â”€ mamba_block.py
â”‚ â”œâ”€â”€ constraint_moe.py
â”‚ â”œâ”€â”€ world_model.py
â”‚ â”œâ”€â”€ decoder_block.py
â”‚ â””â”€â”€ routing_agi_model.py
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ dataset_builder.py
â”‚ â”œâ”€â”€ collator.py
â”‚ â””â”€â”€ milp_targets.py
â”‚
â”œâ”€â”€ training/
â”‚ â”œâ”€â”€ train_loop.py
â”‚ â”œâ”€â”€ optimizer.py
â”‚ â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ model_config.py
â”‚ â””â”€â”€ constraint_registry.py
â”‚
â”œâ”€â”€ RoutingAGI_Training.ipynb
â””â”€â”€ README.md


---

## ğŸš€ Quickstart (Google Colab)

Use the included notebook:

RoutingAGI_Training.ipynb


It provides:

- GitHub cloning  
- dataset + dataloader creation  
- model construction  
- training & evaluation  
- HuggingFace upload support  

---

## ğŸ¯ Research Questions

RoutingAGI enables exploration of questions like:

- Can neural models approximate MILP structure through activations?  
- Do constraint-specific experts improve feasibility prediction?  
- Can world models capture multi-step operational drift?  
- How do Graphormer + Mamba hybrids perform in routing environments?  
- Can differentiable models accelerate search or RL planning?  
- Can this help build AGI-grade routing intelligence?

---

## ğŸ§© Dependencies

- PyTorch  
- NetworkX  
- tqdm  
- huggingface_hub  
- lion-pytorch (optional)

---

## ğŸ“„ License

MIT License.

---

## âœ¨ Author

**Ritwika Kancharla**  
Applied Scientist â€” Neural Optimization & Routing Models ğŸš›ğŸ§ âœ¨

