# ğŸšš RoutingAGI: Neural Optimization for Middle-Mile Logistics  
### Graphormer + Mamba + Constraint-Aware MoE for Large-Scale Routing

RoutingAGI is a research framework exploring **neural surrogates** for middle-mile routing optimization.  
Inspired by real operational challenges in Amazon Transportation (SCOT, ATS, Middle Mile Science), the system blends:

- graph-aware spatial encoders  
- selective state-space sequence models  
- constraint-aligned expert modules  
- learned world-model forecasting  

to approximate MILP-like routing behavior in a differentiable, scalable way.

ğŸ’¡ The goal is to understand whether deep learning can capture the **structure, constraints, and multi-objective trade-offs** fundamental to real logistics networks.

> This project is **research-oriented** â€” intended for experimentation, analysis, and hybrid optimization workflows.

---

## ğŸ” Problem Motivation

Middle-mile routing (FC â†’ SC â†’ DS â†’ Hubs) must respect:

- trailer & container capacity  
- time windows, cutoffs, SLAs  
- lane legality & mode constraints  
- sort-center throughput limits  
- region-level routing policies  
- load balancing  
- trailer & equipment availability  
- multi-objective cost structures  

Traditional MILP optimizers struggle with:

- highly dynamic networks  
- real-time routing decisions  
- multi-step forecasting  
- non-linear congestion effects  
- multi-region combinatorial complexity  

RoutingAGI investigates whether neural models can become **fast differentiable surrogates** capable of:

- estimating feasibility or constraint violations  
- compressing combinatorial decision spaces  
- forecasting routing state evolution  
- supporting RL, heuristics, or hybrid search  
- learning real routing patterns from data  

---

## ğŸ§  Architecture Overview

```
Graphormer Encoder â†’ Mamba Block â†’ Constraint-Aware MoE â†’ World Model â†’ Decoder
```

---

### **1. Graphormer Encoder**
Learns spatial and structural routing information, including:

- facility type embeddings (FC, SC, DS, Hubs)  
- lane legality and mode attributes  
- shortest-path encoding  
- structural centrality and connectivity  
- congestion and throughput signals  

---

### **2. Mamba Block (Selective State-Space Model)**
Handles temporal interactions such as:

- SLA propagation  
- congestion ripple effects  
- equipment availability drift  
- scheduling dependencies  

Mambaâ€™s **dynamic filters + selective gating** allow efficient long-range operational reasoning.

---

### **3. Constraint-Aware MoE Layer**
Each expert corresponds to a MILP constraint, using activation functions aligned with its mathematical shape:

| Constraint | Activation | Rationale |
|-----------|------------|-----------|
| Capacity | ReLU / Softplus | hinge-like overload penalty |
| Time Windows | ReLU | lateness hinge |
| Lane Legality | Sigmoid | binary feasibility |
| Throughput | Tanh / Sigmoid | saturating bottlenecks |
| SLA Risk | Softplus | convex exponential penalty |
| Flow Conservation | Linear | equality constraint |
| Region Rules | Softmax | categorical transitions |
| Load Balancing | Softplus | convex overload |
| Trailer Availability | ReLU | piecewise shortage |

This injects **constraint geometry** directly into the model.

---

## ğŸ“¦ Repository Structure

```
routing_agi/
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ graph_encoder.py
â”‚   â”œâ”€â”€ mamba_block.py
â”‚   â”œâ”€â”€ constraint_moe.py
â”‚   â”œâ”€â”€ world_model.py
â”‚   â”œâ”€â”€ decoder_block.py
â”‚   â””â”€â”€ routing_agi_model.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset_builder.py
â”‚   â”œâ”€â”€ collator.py
â”‚   â””â”€â”€ milp_targets.py
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_loop.py
â”‚   â”œâ”€â”€ optimizer.py
â”‚   â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ model_config.py
â”‚   â””â”€â”€ constraint_registry.py
â”‚
â”œâ”€â”€ RoutingAGI_Training.ipynb
â””â”€â”€ README.md
```

---

## ğŸš€ Quickstart (Google Colab)

Use the included notebook:

```
RoutingAGI_Training.ipynb
```

It provides:

- GitHub cloning  
- dataset & dataloader creation  
- model assembly  
- training + evaluation  
- optional HuggingFace upload  

---

## ğŸ¯ Research Questions

RoutingAGI explores:

- Can neural networks approximate MILP constraint geometry?  
- Do constraint-aligned experts improve feasibility prediction?  
- Can world models capture multi-step operational drift?  
- Are Graphormer + Mamba hybrids effective for routing?  
- Can differentiable surrogates accelerate routing search or RL?  
- What does â€œneural routing intelligenceâ€ look like at scale?  

---

## ğŸ§© Dependencies

- PyTorch  
- NetworkX  
- tqdm  
- huggingface_hub  
- lion-pytorch *(optional)*  

---

## ğŸ“„ License

MIT License.

---

## âœ¨ Author

**Ritwika Kancharla**  
Applied Scientist â€” Neural Optimization & Routing Models
